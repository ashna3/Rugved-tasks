{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "908641c4-f142-43ea-8f6f-49e87605e616",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(imgf, labelf, outf, n):#Function to Convert MNIST image and label files into a CSV format.\n",
    "    \"\"\"Parameters:\n",
    "\n",
    "        imgf: Path to the image file (e.g., train-images.idx3-ubyte).\n",
    "        \n",
    "        labelf: Path to the label file (e.g., train-labels.idx1-ubyte).\n",
    "        \n",
    "        outf: Output CSV file path (e.g., mnist_train.csv).\n",
    "        \n",
    "        n: Number of images to convert.\"\"\"\n",
    "    f = open(imgf, \"rb\")\n",
    "    o = open(outf, \"w\")\n",
    "    l = open(labelf, \"rb\")\n",
    "    #Open the image file, label file and output CSV file in binary read mode (\"rb\"), and write mode (\"w\"), respectively.\n",
    "\n",
    "    #Skip the header information in the image and label files. MNIST image files have a 16-byte header, and label files have an 8-byte header.\n",
    "    f.read(16)\n",
    "    l.read(8)\n",
    "    images = []# Initialize an empty list to store the converted images.\n",
    "\n",
    "    \"\"\"Loop through each image:\n",
    "\n",
    "        Read the label for the current image and convert it to an integer using ord().\n",
    "        \n",
    "        Read each pixel of the image (28x28 = 784 pixels) and append it to the image list.\n",
    "        \n",
    "        Add the complete image to the images list.\"\"\"\n",
    "    for i in range(n):\n",
    "        image = [ord(l.read(1))]#reads 1 byte, converts it into int and initializes image list with label as 1st ele\n",
    "        for j in range(28*28):\n",
    "            image.append(ord(f.read(1)))\n",
    "        images.append(image)\n",
    "\n",
    "    for image in images:# Write each image (including its label) to the output CSV file, with pixels converted to strings separated by commas.\n",
    "        o.write(\",\".join(str(pix) for pix in image)+\"\\n\")\n",
    "    #Close all the opened files.\n",
    "    f.close()\n",
    "    o.close()\n",
    "    l.close()\n",
    "\n",
    "#Convert the training and testing datasets to CSV format.\n",
    "convert(\"train-images.idx3-ubyte\", \"train-labels.idx1-ubyte\",\n",
    "        \"mnist_train.csv\", 60000)\n",
    "convert(\"t10k-images.idx3-ubyte\", \"t10k-labels.idx1-ubyte\",\n",
    "        \"mnist_test.csv\", 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd9dcb7b-e3f7-4107-818a-907e47833619",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b48360-d18f-46ea-8849-2c926bf862ca",
   "metadata": {},
   "source": [
    " Loading Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36f508c8-4980-41a8-94f6-c214f91e7abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test=pd.read_csv(\"mnist_test.csv\")#Loads the converted test dataset from the CSV file into a pandas DataFrame named data_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "407d2184-c5be-4047-88b8-e469974f6a13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>7</th>\n",
       "      <th>0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>...</th>\n",
       "      <th>0.658</th>\n",
       "      <th>0.659</th>\n",
       "      <th>0.660</th>\n",
       "      <th>0.661</th>\n",
       "      <th>0.662</th>\n",
       "      <th>0.663</th>\n",
       "      <th>0.664</th>\n",
       "      <th>0.665</th>\n",
       "      <th>0.666</th>\n",
       "      <th>0.667</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   7  0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  ...  0.658  0.659  0.660  \\\n",
       "0  2  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "1  1  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "2  0  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "3  4  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "4  1  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "\n",
       "   0.661  0.662  0.663  0.664  0.665  0.666  0.667  \n",
       "0      0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0      0  \n",
       "3      0      0      0      0      0      0      0  \n",
       "4      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.head()#1st col:labels(2,1,0,4,1,.);remaining:pixel values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e715a3-ad60-4242-bd02-d0135934a24e",
   "metadata": {},
   "source": [
    "Loading train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ecb9aef-4ea5-4c3e-9aa3-b2e7b585bf4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5</th>\n",
       "      <th>0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>...</th>\n",
       "      <th>0.608</th>\n",
       "      <th>0.609</th>\n",
       "      <th>0.610</th>\n",
       "      <th>0.611</th>\n",
       "      <th>0.612</th>\n",
       "      <th>0.613</th>\n",
       "      <th>0.614</th>\n",
       "      <th>0.615</th>\n",
       "      <th>0.616</th>\n",
       "      <th>0.617</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   5  0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  ...  0.608  0.609  0.610  \\\n",
       "0  0  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "1  4  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "2  1  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "3  9  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "4  2  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "\n",
       "   0.611  0.612  0.613  0.614  0.615  0.616  0.617  \n",
       "0      0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0      0  \n",
       "3      0      0      0      0      0      0      0  \n",
       "4      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train=pd.read_csv(\"mnist_train.csv\")#Loads the converted training dataset from the CSV file into a pandas DataFrame named data_train.\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55b18922-3623-4ef7-8f0f-45e39123995a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59999 785\n"
     ]
    }
   ],
   "source": [
    "m,n=data_train.shape\n",
    "print(m,n)#checking for no. of training images and each image's data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b652b611-55ce-4425-ba81-d212e0eeddbb",
   "metadata": {},
   "source": [
    "Transpose the arrays so that each column represents an image, which is useful for matrix operations in neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc0b2522-a296-49ce-8bf5-7f8cdb6355b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(785, 59999)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_array=np.array(data_train)#Converts the data_train DataFrame into a numpy array named data_train_array.\n",
    "data_train_array=data_train_array.T#Transposes the data_train_array. This operation swaps the rows with columns.\n",
    "data_train_array.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1af7628-5883-4561-9516-3c30c615bccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(785, 9999)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test_array=np.array(data_test)\n",
    "data_test_array=data_test_array.T\n",
    "data_test_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9a26096-d9fb-470a-9340-f9776e881a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=data_train_array[0]# Extracts the first row of data_train_array and assigns it to y_train.\n",
    "x_train=data_train_array[1:n]#Extracts rows from the second row to the n-1 row of data_train_array and assigns them to x_train\n",
    "x_train=x_train/255 #Normalizes the pixel values in x_train by dividing them by 255.\n",
    "y_test=data_test_array[0]#Extracts the first row of data_test_array and assigns it to y_test\n",
    "x_test=data_test_array[1:n]#Extracts rows from the second row to the n-1 row of data_test_array and assigns them to x_test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fb81d33-6da5-4cc8-8333-3b62fd062b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:,0].shape#all rows and 1st col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70b3bcb5-ef46-4e7a-8c4b-549ef488eafc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 59999)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dabdb1dc-51e0-40ac-8438-0d868a5b2fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59999"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7110d9c2-6d68-4f5d-8bb7-b5c232d269f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.max(0)#max label value in the array of no.s 0-9 is 9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c5f976-59c6-45c0-8dc9-154deb5c62eb",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "558578fa-3b46-4754-a9eb-def24bdb9cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_parameters():# Defines a function to initialize the parameters of the neural network.\n",
    "    w1=np.random.rand(10, 784)-0.5\n",
    "    #Initializes the weights for the first layer (w1) as a matrix of random values between -0.5 and 0.5. The shape is (10, 784), meaning there are 10 output neurons and 784 input neurons (28x28 images).\n",
    "    b1=np.random.rand(10, 1)-0.5\n",
    "    #Initializes the biases for the first layer (b1) as a column vector of random values between -0.5 and 0.5.\n",
    "    w2=np.random.rand(10, 10)-0.5\n",
    "    #Initializes the weights for the second layer (w2) as a matrix of random values between -0.5 and 0.5.\n",
    "    b2=np.random.rand(10, 1)-0.5\n",
    "    #Initializes the biases for the second layer (b2) as a column vector of random values between -0.5 and 0.5.\n",
    "    return w1,w2,b1,b2\n",
    "\n",
    "def ReLU(x):#Defines a function named ReLU that applies the ReLU (Rectified Linear Unit) activation to the input x.\n",
    "    return np.maximum(x,0)#This means that any input value less than 0 is set to 0, and any input value greater than or equal to 0 remains unchanged.\n",
    "\n",
    "def softmax(x):#Defines a function named softmax that applies the softmax activation to the input x.\n",
    "   # Used in the output layer for multi-class classification problems to ensure outputs sum up to 1, representing probabilities.\n",
    "    exp_x = np.exp(x - np.max(x)) #Computes the exponential of each element in x.\n",
    "    return exp_x / np.sum(exp_x)#Returns the softmax output, which is the exponential of x divided by the sum of exponentials of all elements in x.\n",
    "\n",
    "def forward_prop(w1,w2,b1,b2,x):#Defines a function named forward_prop that performs the forward propagation through the neural network.\n",
    "    #Computes the output of the network for a given input by passing it through each layer.\n",
    "    z1 = np.dot(w1, x) + b1#Computes the weighted sum (z1) for the first layer by multiplying the weights (w1) with the input (x) and adding the bias (b1).\n",
    "    A1 = ReLU(z1)#Applies the ReLU activation function to z1 to get the output of the first layer (A1).\n",
    "    \n",
    "    z2 = np.dot(w2, A1) + b2#Computes the weighted sum (z2) for the second layer by multiplying the weights (w2) with the output of the first layer (A1) and adding the bias (b2).\n",
    "    A2 = softmax(z2)# Applies the softmax activation function to z2 to get the final output (A2) of the network.\n",
    "   \n",
    "    return z1, z2, A1, A2\n",
    "\n",
    "\n",
    "def one_hot_encode(y):#Converts categorical labels into a numerical representation that can be processed by the network.\n",
    "    one_hot_y=np.zeros((y.size,(y.max()+1)))#Initializes a matrix filled with zeros for one-hot encoding.\n",
    "   \n",
    "    i=np.arange(y.size)# Sets the appropriate column of each row to 1 based on the label value.\n",
    "    one_hot_y[i,y]=1#Sets the corresponding column to 1 for each label.\n",
    "    one_hot_y=one_hot_y.T#Transposes the one-hot encoded matrix.\n",
    "    return one_hot_y\n",
    "\n",
    "def der_relu(z):#Defines the derivative of the ReLU activation function used in backpropagation.\n",
    "   return z>0#Returns a boolean array indicating where z is greater than 0.\n",
    "    \n",
    "def back_prop(z1,z2,A1,A2,w2,x,y):#Computes the gradients of the loss with respect to each parameter in the network.\n",
    "    m = y.size#Gets the number of examples.\n",
    "    one_hot_y = one_hot_encode(y)#One-hot encodes the labels.\n",
    "    dz2 = A2 - one_hot_y#Computes the error gradient for the output layer.\n",
    "    \n",
    "    dw2 = np.dot(dz2, A1.T) / m #Computes the gradient of the loss with respect to the weights of the second layer.\n",
    "    db2 = np.sum(dz2) / m #Computes the gradient of the loss with respect to the bias of the second layer.\n",
    "    dz1 = np.dot(w2.T, dz2) * der_relu(z1) #Computes the error gradient for the first layer.\n",
    "    dw1 = np.dot(dz1, x.T) / m #Computes the gradient of the loss with respect to the weights of the first layer.\n",
    "    db1 = np.sum(dz1) / m #Computes the gradient of the loss with respect to the bias of the first layer.\n",
    "    return dw1,dw2,db1,db2\n",
    "\n",
    "def update_param(w1,w2,b1,b2,dw1,dw2,db2,db1,a):#Defines a function to update the parameters using gradients and a learning rate.\n",
    "    w1=w1-a*dw1#Updates the weights of the first layer.\n",
    "    w2=w2-a*dw2#Updates the weights of the second layer.\n",
    "    b1=b1-a*db1#Updates the bias of the first layer.\n",
    "    b2=b2-a*db2#Updates the bias of the second layer.\n",
    "    return w1,w2,b1,b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c607d51f-a54b-4bbe-a59f-63a79fe5abb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predict(A2):#Defines a function named get_predict that returns the predicted labels based on the output of the network (A2).\n",
    "    return np.argmax(A2,0)#Returns the indices of the maximum values along the first axis (axis=0) of A2, which correspond to the predicted labels.\n",
    "\n",
    "def accuracy(pred, y):#Defines a function named accuracy that calculates the accuracy of the model by comparing predictions (pred) with actual labels (y).\n",
    "    print(pred,y)\n",
    "    return np.sum(pred==y)/y.size#Returns the accuracy as the ratio of correctly predicted labels to the total number of labels.\n",
    "\n",
    "def gradient_decend(x,y,epochs,lr):#Defines a function named gradient_decend that trains the neural network using gradient descent.\n",
    "    w1,w2,b1,b2=init_parameters()#Initializes the weights and biases of the network using the init_parameters function.\n",
    "    for i in range (epochs):# Loops through each training epoch.\n",
    "        # An epoch is a term used in machine learning to describe the process of training a model on the entire training dataset once.\n",
    "        z1,z2,A1,A2=forward_prop(w1,w2,b1,b2,x)#Performs forward propagation to compute the outputs of the network.\n",
    "        dw1,dw2,db1,db2=back_prop(z1,z2,A1,A2,w2,x,y)#Calls the forward_prop function to get the intermediate results (z1, z2, A1, A2).\n",
    "        w1,w2,b1,b2=update_param(w1,w2,b1,b2,dw1,dw2,db2,db1,lr)#Performs backward propagation to compute the gradients.\n",
    "        if(i%50==0):#hecks if the current epoch is a multiple of 50.\n",
    "            print(\"epochs=\",i)\n",
    "            print(\"accuracy=\",accuracy(get_predict(A2),y))#Prints the accuracy of the model at the current epoch.\n",
    "    return w1,w2,b1,b2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5973543b-61b3-4673-b5cf-6862736d5fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs= 0\n",
      "[8 8 2 ... 8 8 2] [0 4 1 ... 5 6 8]\n",
      "accuracy= 0.10200170002833381\n",
      "epochs= 50\n",
      "[0 0 0 ... 0 0 0] [0 4 1 ... 5 6 8]\n",
      "accuracy= 0.09870164502741713\n",
      "epochs= 100\n",
      "[0 0 0 ... 0 0 0] [0 4 1 ... 5 6 8]\n",
      "accuracy= 0.09870164502741713\n",
      "epochs= 150\n",
      "[0 0 0 ... 0 0 0] [0 4 1 ... 5 6 8]\n",
      "accuracy= 0.09870164502741713\n",
      "epochs= 200\n",
      "[0 0 0 ... 0 0 0] [0 4 1 ... 5 6 8]\n",
      "accuracy= 0.09870164502741713\n",
      "epochs= 250\n",
      "[0 0 0 ... 0 0 0] [0 4 1 ... 5 6 8]\n",
      "accuracy= 0.09870164502741713\n",
      "epochs= 300\n",
      "[0 0 0 ... 0 0 0] [0 4 1 ... 5 6 8]\n",
      "accuracy= 0.09870164502741713\n",
      "epochs= 350\n",
      "[0 0 0 ... 0 0 0] [0 4 1 ... 5 6 8]\n",
      "accuracy= 0.09870164502741713\n",
      "epochs= 400\n",
      "[0 0 0 ... 0 0 0] [0 4 1 ... 5 6 8]\n",
      "accuracy= 0.09870164502741713\n",
      "epochs= 450\n",
      "[0 0 0 ... 0 0 0] [0 4 1 ... 5 6 8]\n",
      "accuracy= 0.09870164502741713\n",
      "epochs= 500\n",
      "[0 0 0 ... 0 0 0] [0 4 1 ... 5 6 8]\n",
      "accuracy= 0.09870164502741713\n",
      "epochs= 550\n",
      "[0 0 0 ... 0 0 0] [0 4 1 ... 5 6 8]\n",
      "accuracy= 0.09870164502741713\n",
      "epochs= 600\n",
      "[0 0 0 ... 0 0 0] [0 4 1 ... 5 6 8]\n",
      "accuracy= 0.09870164502741713\n",
      "epochs= 650\n",
      "[0 0 0 ... 0 0 0] [0 4 1 ... 5 6 8]\n",
      "accuracy= 0.09870164502741713\n",
      "epochs= 700\n",
      "[0 0 0 ... 0 0 0] [0 4 1 ... 5 6 8]\n",
      "accuracy= 0.09870164502741713\n",
      "epochs= 750\n",
      "[0 0 0 ... 0 0 0] [0 4 1 ... 5 6 8]\n",
      "accuracy= 0.09870164502741713\n",
      "epochs= 800\n",
      "[0 0 0 ... 0 0 0] [0 4 1 ... 5 6 8]\n",
      "accuracy= 0.09870164502741713\n",
      "epochs= 850\n",
      "[0 0 0 ... 0 0 0] [0 4 1 ... 5 6 8]\n",
      "accuracy= 0.09870164502741713\n",
      "epochs= 900\n",
      "[0 0 0 ... 0 0 0] [0 4 1 ... 5 6 8]\n",
      "accuracy= 0.09870164502741713\n",
      "epochs= 950\n",
      "[0 0 0 ... 0 0 0] [0 4 1 ... 5 6 8]\n",
      "accuracy= 0.09870164502741713\n",
      "epochs= 1000\n",
      "[0 0 0 ... 0 0 0] [0 4 1 ... 5 6 8]\n",
      "accuracy= 0.09870164502741713\n",
      "epochs= 1050\n",
      "[0 0 0 ... 0 0 0] [0 4 1 ... 5 6 8]\n",
      "accuracy= 0.09870164502741713\n",
      "epochs= 1100\n",
      "[0 0 0 ... 0 0 0] [0 4 1 ... 5 6 8]\n",
      "accuracy= 0.09870164502741713\n",
      "epochs= 1150\n",
      "[0 0 0 ... 0 0 0] [0 4 1 ... 5 6 8]\n",
      "accuracy= 0.09870164502741713\n",
      "epochs= 1200\n",
      "[0 0 0 ... 0 0 0] [0 4 1 ... 5 6 8]\n",
      "accuracy= 0.09870164502741713\n",
      "epochs= 1250\n",
      "[0 0 0 ... 0 0 0] [0 4 1 ... 5 6 8]\n",
      "accuracy= 0.09870164502741713\n",
      "epochs= 1300\n",
      "[0 0 0 ... 0 0 0] [0 4 1 ... 5 6 8]\n",
      "accuracy= 0.09870164502741713\n",
      "epochs= 1350\n",
      "[0 0 0 ... 0 0 0] [0 4 1 ... 5 6 8]\n",
      "accuracy= 0.09870164502741713\n",
      "epochs= 1400\n",
      "[0 0 0 ... 0 0 0] [0 4 1 ... 5 6 8]\n",
      "accuracy= 0.09870164502741713\n",
      "epochs= 1450\n",
      "[0 0 0 ... 0 0 0] [0 4 1 ... 5 6 8]\n",
      "accuracy= 0.09870164502741713\n",
      "epochs= 1500\n",
      "[0 0 0 ... 0 0 0] [0 4 1 ... 5 6 8]\n",
      "accuracy= 0.09870164502741713\n",
      "epochs= 1550\n",
      "[0 0 0 ... 0 0 0] [0 4 1 ... 5 6 8]\n",
      "accuracy= 0.09870164502741713\n",
      "epochs= 1600\n",
      "[0 0 0 ... 0 0 0] [0 4 1 ... 5 6 8]\n",
      "accuracy= 0.09870164502741713\n",
      "epochs= 1650\n",
      "[0 0 0 ... 0 0 0] [0 4 1 ... 5 6 8]\n",
      "accuracy= 0.09870164502741713\n",
      "epochs= 1700\n",
      "[0 0 0 ... 0 0 0] [0 4 1 ... 5 6 8]\n",
      "accuracy= 0.09870164502741713\n",
      "epochs= 1750\n",
      "[0 0 0 ... 0 0 0] [0 4 1 ... 5 6 8]\n",
      "accuracy= 0.09870164502741713\n",
      "epochs= 1800\n",
      "[0 0 0 ... 0 0 0] [0 4 1 ... 5 6 8]\n",
      "accuracy= 0.09870164502741713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ashna\\AppData\\Local\\Temp\\ipykernel_16584\\3254437655.py:17: RuntimeWarning: invalid value encountered in subtract\n",
      "  exp_x = np.exp(x - np.max(x)) #Computes the exponential of each element in x.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs= 1850\n",
      "[0 0 0 ... 0 0 0] [0 4 1 ... 5 6 8]\n",
      "accuracy= 0.0987183119718662\n",
      "epochs= 1900\n",
      "[0 0 0 ... 0 0 0] [0 4 1 ... 5 6 8]\n",
      "accuracy= 0.0987183119718662\n",
      "epochs= 1950\n",
      "[0 0 0 ... 0 0 0] [0 4 1 ... 5 6 8]\n",
      "accuracy= 0.0987183119718662\n"
     ]
    }
   ],
   "source": [
    "w1,w2,b1,b2=gradient_decend(x_train,y_train,2000,0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6522d2a0-c02b-42f6-8fc1-8054b02019a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(x,w1,w2,b1,b2):\n",
    "    z1,z2,A1,A2=forward_prop(w1,w2,b1,b2,x)\n",
    "    return np.argmax(A2,0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04a4f9ad-52e9-43f3-b8e1-cf6cdfb5d233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0] [2 1 0 ... 4 5 6]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.09800980098009801"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predic=pred(x_test,w1,w2,b1,b2)\n",
    "accuracy(predic,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35de72c-a439-47af-b13b-37e4a8a5a55a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
